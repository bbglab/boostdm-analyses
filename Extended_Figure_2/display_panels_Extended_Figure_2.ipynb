{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH_SOURCE_DATA'] = '/workspace/projects/boostdm/nature-release/source-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('./scripts/')\n",
    "import glob\n",
    "import gzip\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc\n",
    "from matplotlib import cm\n",
    "cmap = cm.RdYlGn_r\n",
    "\n",
    "import conf\n",
    "import oncotree\n",
    "from feature_complexity import linear_complexity, shap_pca_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Figure 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "prediction_folder = os.path.join(conf.output_boostdm, 'saturation', 'prediction')\n",
    "df_drivers = pd.read_csv(conf.drivers_path, sep='\\t')\n",
    "role_dict = dict(list(map(tuple, df_drivers[['SYMBOL', 'ROLE']].drop_duplicates().values.tolist())))\n",
    "df = pd.read_csv(os.path.join(conf.output_boostdm, 'discovery', 'discovery.tsv'), sep='\\t')\n",
    "df['linear_complexity'] = df.apply(lambda r: linear_complexity(r['gene'], r['ttype'], prediction_folder), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single variance explained\n",
    "\n",
    "def variance_explained_plot(gene, ttype):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    \n",
    "    y = shap_pca_plot(gene, ttype, prediction_folder)\n",
    "    x = range(len(y))\n",
    "    \n",
    "    ax.plot(y, '--', label=f'{gene}: {ttype}', lw=3, alpha=1., c=conf.dict_colors_role[role_dict[gene]])\n",
    "    ax.fill_between(x, 1, y, alpha=0.2, color=conf.dict_colors_role[role_dict[gene]])\n",
    "    ax.set_ylabel('between y1 and 0')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'SHAP PCA\\n{gene}: {ttype}')\n",
    "    ax.set_xlabel('Number of PCs')\n",
    "    ax.set_ylabel('Proportion of Variance Explained')\n",
    "    \n",
    "    plt.savefig(f'./raw_plots/pca-varexplained.{gene}.{ttype}.svg', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained_plot('TP53', 'LUSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained_plot('KRAS', 'PAAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated = df[~df['linear_complexity'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance explained for several cases at once\n",
    "\n",
    "def several_variance_explained(*gene_ttype_args):\n",
    "    \n",
    "    for i, (gene, ttype) in enumerate(gene_ttype_args):\n",
    "        \n",
    "        y = shap_pca_plot(gene, ttype, prediction_folder)\n",
    "        \n",
    "        color = conf.dict_colors_role[role_dict[gene]]\n",
    "        \n",
    "        i = df_annotated[(df_annotated['gene'] == gene) & (df_annotated['ttype'] == ttype)].index[0]\n",
    "        complexity = df_annotated.loc[i, 'linear_complexity']\n",
    "        ax.plot(y[:11], label=f'{gene}: {ttype}: {complexity:.2f}', lw=5, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "l = [('KRAS', 'LUAD'), ('RB1', 'BLCA'), ('CTNNB1', 'HC'), ('EGFR', 'LUAD'),  \n",
    "     ('EGFR', 'GBM'), ('TP53', 'LUSC')]\n",
    "several_variance_explained(*l)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title(f'SHAP PCA')\n",
    "ax.set_xlabel('Number of PCs')\n",
    "ax.set_ylabel('Proportion of Variance Explained')\n",
    "plt.legend()\n",
    "plt.savefig(f'./raw_plots/shap.pca.several.svg', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Figure 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [os.path.join(conf.output_boostdm, 'uniform-downsamples', 'output_1')] + \\\n",
    "          [os.path.join(conf.output_boostdm, 'uniform-downsamples', f'output_downsampling_{perc}') for perc in range(95, 10, -5)]\n",
    "            \n",
    "prediction_folders = list(map(lambda x: os.path.join(x, 'saturation', 'prediction'), outputs))\n",
    "evaluation_folders = list(map(lambda x: os.path.join(x, 'evaluation'), outputs))\n",
    "\n",
    "\n",
    "def get_size_perf(gene, ttype, evaluation_folder, metric='fscore50'):\n",
    "    \n",
    "    fn = os.path.join(evaluation_folder, ttype, f'{gene}.eval.pickle.gz')\n",
    "    with gzip.open(fn, 'rb') as g:\n",
    "        eval_dict = pickle.load(g)\n",
    "\n",
    "    return eval_dict[metric], eval_dict['size']\n",
    "\n",
    "\n",
    "def downsampling_with_complexity(gene, ttype, prediction_folders, evaluation_folders):\n",
    "\n",
    "    complexities = []\n",
    "    perf = []\n",
    "    high = []\n",
    "    low = []\n",
    "    size = []\n",
    "\n",
    "    for i, (pred_folder, eval_folder) in enumerate(zip(prediction_folders, evaluation_folders)):\n",
    "        complexities.append(linear_complexity(gene, ttype, pred_folder, suffix='80.30.tsv.gz'))\n",
    "        perfs, sizes = get_size_perf(gene, ttype, eval_folder)\n",
    "        perf.append(np.nanmedian(perfs))\n",
    "        high.append(np.nanpercentile(perfs, 75))\n",
    "        low.append(np.nanpercentile(perfs, 25))\n",
    "        size.append(i)\n",
    "        \n",
    "    # plotting\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,3))\n",
    "    ax.set_xticks(size)\n",
    "    ax.set_xticklabels(['full'] + list(map(lambda x: str(x) + '%', range(95, 5, -5))), rotation=90)\n",
    "    \n",
    "    p = plt.scatter(size, perf, cmap=cmap, c=complexities, vmin=0., vmax=0.4, s=200, alpha=1, edgecolors='black')\n",
    "    cbar = fig.colorbar(p)\n",
    "    cbar.ax.set_ylabel('Feature Complexity', rotation=270, labelpad=15)\n",
    "    color = p.get_facecolors()[0].tolist()\n",
    "    \n",
    "    lows = list(zip(size, low))\n",
    "    highs = list(zip(size, high))\n",
    "    lines =  list(zip(lows, highs))\n",
    "    lc = mc.LineCollection(lines, linewidths=1, alpha=1, colors=color)\n",
    "    ax.add_collection(lc)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_title(f'{gene}:{ttype}')\n",
    "    ax.set_ylabel('F-score')\n",
    "    ax.set_xlabel('cohort-wise downsampling')\n",
    "    \n",
    "    ax.set_ylim(0.6,)\n",
    "    \n",
    "    plt.savefig(f'./raw_plots/{gene}.{ttype}.performance.complexity.svg', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_with_complexity('TP53', 'LUAD', prediction_folders, evaluation_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_with_complexity('PTEN', 'UCEC', prediction_folders, evaluation_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_with_complexity('VHL', 'RCCC', prediction_folders, evaluation_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Figure 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets = os.path.join(conf.output_boostdm, 'create_datasets')\n",
    "output_sampleholdout = os.path.join(conf.output_boostdm, 'sample-holdout/output_10')\n",
    "prediction_folder = os.path.join(output_sampleholdout, 'saturation', 'prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = oncotree.Oncotree()\n",
    "leaves = tree.get_ttypes('CANCER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific = []\n",
    "for fn in tqdm(glob.glob(os.path.join(prediction_folder, '*.*.prediction.tsv.gz'))):\n",
    "    gene, _ = tuple(os.path.basename(fn).split('.')[:2])\n",
    "    df = pd.read_csv(fn, sep='\\t')\n",
    "    ttype = df['selected_model_ttype'].values[0]\n",
    "    if ttype in leaves:\n",
    "        specific.append((gene, ttype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate tumor type\n",
    "\n",
    "drivers = pd.read_csv(conf.drivers_path, sep='\\t')\n",
    "role_dict = dict(zip(drivers['SYMBOL'].values, drivers['ROLE'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load held-out mutations\n",
    "\n",
    "holdout_fn = os.path.join(conf.output_boostdm, 'sample-holdout', 'sampleholdout.10.tsv')\n",
    "holdout_data = pd.read_csv(holdout_fn, sep='\\t')\n",
    "\n",
    "cohort_ttype_dict = dict(zip(drivers['COHORT'], drivers['CANCER_TYPE']))\n",
    "holdout_data['ttype'] = holdout_data['COHORT'].apply(lambda x: cohort_ttype_dict.get(x, None))\n",
    "holdout_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "# annotate driver/passenger\n",
    "\n",
    "all_cohorts = []\n",
    "\n",
    "for cohort in tqdm(holdout_data.COHORT.unique()):\n",
    "    holdout_cohort = holdout_data[holdout_data['COHORT'] == cohort]\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(create_datasets, f'{cohort}.regression_data.tsv'), sep='\\t')\n",
    "    except FileNotFoundError:\n",
    "        print(cohort)\n",
    "        continue\n",
    "    df['chr'] = df['chr'].astype(str)\n",
    "    df['pos'] = df['pos'].astype(int)\n",
    "    holdout_cohort = holdout_cohort.merge(df[['chr', 'pos', 'ref', 'alt', 'gene', 'response']], on=['chr', 'pos', 'ref', 'alt', 'gene'], how='outer', indicator=True)\n",
    "    holdout_cohort = holdout_cohort[holdout_cohort['_merge'].isin(['left_only', 'both'])]\n",
    "    holdout_cohort = holdout_cohort.drop(columns=['_merge'])\n",
    "    holdout_cohort['response'] = holdout_cohort['response'].fillna(0)\n",
    "    all_cohorts.append(holdout_cohort)\n",
    "\n",
    "all_cohorts = pd.concat(all_cohorts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cohorts_effective = all_cohorts[all_cohorts.apply(lambda r: (r['gene'], r['ttype']), axis=1).isin(specific)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = []\n",
    "for gene, ttype in tqdm(specific):\n",
    "    df = pd.read_csv(os.path.join(prediction_folder, f'{gene}.{ttype}.prediction.tsv.gz'), sep='\\t')\n",
    "    dg = all_cohorts_effective[(all_cohorts_effective['gene'] == gene) & (all_cohorts_effective['ttype'] == ttype)]\n",
    "    dg = dg.merge(df[['pos', 'alt', 'gene', 'boostDM_score']], on=['pos', 'alt', 'gene'])\n",
    "    merged.append(dg)\n",
    "merged = pd.concat(merged, axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbeta(r, beta=0.5):\n",
    "    \n",
    "    \"\"\"\n",
    "    beta is chosen such that recall is considered \n",
    "    beta times as important as precision\n",
    "    \"\"\"\n",
    "    \n",
    "    p = 1 + beta ** 2\n",
    "    \n",
    "    try:\n",
    "        return (p * r['TP']) / ((p * r['TP']) + (p - 1) * r['FN'] + r['FP'])\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion(df, prediction, response):\n",
    "    \n",
    "    p = df[prediction].values >= 0.5\n",
    "    r = df[response].values\n",
    "    \n",
    "    df[f'TP'] = p * r\n",
    "    df[f'FP'] = p * (1 - r)\n",
    "    df[f'TN'] = (1 - p) * (1 - r)\n",
    "    df[f'FN'] = (1 - p) * r\n",
    "    \n",
    "    return df\n",
    "\n",
    "merged = get_confusion(merged, 'boostDM_score', 'response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged.drop_duplicates().groupby(['gene', 'ttype']).sum()[['TP', 'FP', 'TN', 'FN']].reset_index()\n",
    "df['fscore50_holdout'] = df.apply(get_fbeta, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get gene-ttype F-score\n",
    "\n",
    "evaluation = os.path.join(conf.output_boostdm, 'evaluation')\n",
    "\n",
    "def retrieve_fscore(gene, ttype):\n",
    "    try:\n",
    "        with gzip.open(os.path.join(evaluation, ttype, f'{gene}.eval.pickle.gz'), 'rb') as g:\n",
    "            d = pickle.load(g)\n",
    "        score = np.nanmedian(d['fscore50'])\n",
    "        score_up = np.nanpercentile(d['fscore50'], 75)\n",
    "        score_down = np.nanpercentile(d['fscore50'], 25)\n",
    "    except FileNotFoundError:\n",
    "        score, score_up, score_down = None, None, None\n",
    "    return score, score_up, score_down\n",
    "\n",
    "df['fscore50_original'], df['fscore50_original_up'], df['fscore50_original_down'] = zip(*df.apply(lambda r: retrieve_fscore(r['gene'], r['ttype']), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_sample_holdout(moa, title, outfn):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(3,3))\n",
    "    box = [df[df.apply(lambda x: role_dict[x['gene']], \n",
    "                       axis=1).isin([moa])]['fscore50_original'].values, \n",
    "           df[df.apply(lambda x: role_dict[x['gene']], \n",
    "                       axis=1).isin([moa])]['fscore50_holdout'].values]\n",
    "    x = [1] * len(box[0]) + [2] * len(box[1])\n",
    "    x = x + np.random.normal(0, 0.01, size=len(x))\n",
    "    y = list(box[0]) + list(box[1])\n",
    "    ax.scatter(x, y, alpha=0.3, s=10)\n",
    "    ax.boxplot(box, showfliers=False, widths=0.5)\n",
    "    ax.set_xticklabels(['full model\\n(cross-validation)', 'hold-out'])\n",
    "    ax.set_ylabel('F-score50')\n",
    "    ax.set_title(f'{title} (n={len(box[0])})')\n",
    "    ax.set_ylim(0.7, 1.01)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.savefig(f'./raw_plots/{outfn}', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return mannwhitneyu(box[0], box[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " boxplot_sample_holdout('LoF', 'Tumor suppressors', 'sampleholdout.tumor-suppressors.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " boxplot_sample_holdout('Act', 'Oncogenes', 'sampleholdout.oncogenes.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "\n",
    "def plot_gene(gene):\n",
    "\n",
    "    dg = df[(df['gene'] == gene)]\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.scatter(dg['fscore50_original'], dg['fscore50_holdout'], s=100, alpha=0.5)\n",
    "    for i, ttype in enumerate(dg['ttype'].values):\n",
    "        x = dg['fscore50_original'].values[i]\n",
    "        y = dg['fscore50_holdout'].values[i]\n",
    "        x_up = dg['fscore50_original_up'].values[i] \n",
    "        x_down = dg['fscore50_original_down'].values[i]\n",
    "\n",
    "        upper = list(zip([x_up], [y]))\n",
    "        lower = list(zip([x_down], [y]))\n",
    "        lines = list(zip(lower, upper))\n",
    "        lc = mc.LineCollection(lines, linewidths=3, alpha=0.5)\n",
    "        ax.add_collection(lc)\n",
    "\n",
    "        ax.text(dg['fscore50_original'].values[i] + 0.01, \n",
    "                dg['fscore50_holdout'].values[i] + 0.01, f'{ttype}')\n",
    "    ax.plot([0.75, 1], [0.75, 1], '--')\n",
    "    ax.set_title(gene)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_xlabel('cross-validation (F-score50) with IQ range')\n",
    "    ax.set_ylabel('sample hold-out (F-score50)')\n",
    "    plt.savefig(f'./raw_plots/{gene}.sampleholdout.10.svg', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gene('TP53')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-boosting_env]",
   "language": "python",
   "name": "conda-env-anaconda3-boosting_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
